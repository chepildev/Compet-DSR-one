{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Pipeline**\n",
    "\n",
    "| **Steps**                                              | **Script files**                          |\n",
    "|-----------------------------------------------------------|-------------------------------------------|\n",
    "| 1) Read and pre-process data                              | pre_processing.py                         |\n",
    "| 2) Feature engineering                                    | feature_engineering.py                    |\n",
    "| 3) Train models                                           | model_training.py, <br>tree_model_training.py |\n",
    "| 4) Predict on test_features <br>and write submission file | final_predict.py                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.pre_processing as pp\n",
    "import scripts.feature_engineering as fe\n",
    "import scripts.model_evaluation as me\n",
    "from scripts.model_training import Model\n",
    "from scripts.tree_model_training import rf_model\n",
    "from scripts.model_evaluation import regression_evaluation\n",
    "import scripts.final_predict as fp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files \n",
    "train_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "train_target = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train_target\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(train_target['total_cases'])\n",
    "# plt.title('Total Cases')\n",
    "# plt.show()\n",
    "\n",
    "# show missing values in train_target\n",
    "# print(train_target['total_cases'].isnull().sum())\n",
    "\n",
    "# show missing values in train_features\n",
    "# print(train_features.isnull().sum())\n",
    "\n",
    "# sum total rows\n",
    "print(train_features.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=False)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=False)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=False)\n",
    "\n",
    "# Run checks for missing values\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "print(f'train_iq shape: {train_iq.shape}') \n",
    "print(f'train_sj shape: {train_sj.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogdata = data\n",
    "data\n",
    "ogdata['total_cases'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.feature_engineering import rolling_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ra = fe.rolling_avg(data, 'total_cases', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weighted exponential moving average\n",
    "# pd.ewm(data['total_cases'], span=4)\n",
    "data['total_cases'].ewm(span=9).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a weighted exponential moving average to 'total_cases' column\n",
    "# fe.ewm(data, 'total_cases', 4)\n",
    "def exp_weight_moving(data, column, span):\n",
    "    \"\"\"Convert column total_cases to rolling average\n",
    "\n",
    "    Args: Dataframe, column name, window size\n",
    "\n",
    "    Returns: Dataframe with rolling average overwritting column\n",
    "\n",
    "    \"\"\"\n",
    "    data[column] = data[column].ewm(span=span).mean()\n",
    "\n",
    "    return data\n",
    "\n",
    "exp_weight_moving(data, 'total_cases', 14)['total_cases']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogdata['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ewma = exp_weight_moving(data, 'total_cases', 14)['total_cases']\n",
    "# plot over original total_cases\n",
    "df_tc = data['total_cases']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_tc)\n",
    "type(df_ewma)\n",
    "type(df_ra['total_cases'])\n",
    "# df_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_ewma, color='red')\n",
    "plt.plot(df_tc, color='blue')\n",
    "plt.plot(df_ra['total_cases'], color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear all directories\n",
    "# %reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_cases'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sj.head()\n",
    "type(train_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature engineering \n",
    "train_iq = fe.cyclical_encode_date(train_iq)\n",
    "train_sj = fe.cyclical_encode_date(train_sj)\n",
    "\n",
    "train_iq = fe.drop_date(train_iq)\n",
    "train_sj = fe.drop_date(train_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train_sj to dataframe\n",
    "dftrain_sj = pd.DataFrame(train_sj)\n",
    "dftrain_sj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veiw the column index ndvi_ne from train_sj\n",
    "train_sj['ndvi_ne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and cross-validation sets\n",
    "X_train_sj, y_train_sj, X_test_sj, y_test_sj = pp.train_cv_split(train_sj, city='sj')\n",
    "X_train_iq, y_train_iq, X_test_iq, y_test_iq = pp.train_cv_split(train_iq, city='iq')\n",
    "\n",
    "# Check compatible sizes for models:\n",
    "assert len(X_train_sj) == len(y_train_sj)\n",
    "assert len(X_test_sj) == len(y_test_sj)\n",
    "assert len(X_train_iq) == len(y_train_iq)\n",
    "assert len(X_test_iq) == len(y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with sklearn \n",
    "tss = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "X_iq = train_iq.drop(labels=['total_cases'], axis=1)\n",
    "y_iq = train_iq['total_cases']\n",
    "X_sj = train_sj.drop(labels=['total_cases'], axis=1)\n",
    "y_sj = train_sj['total_cases']\n",
    "\n",
    "for train_index, test_index in tss.split(X_iq):\n",
    "    X_train, X_test = X_iq.iloc[train_index, :], X_iq.iloc[test_index,:]\n",
    "    y_train, y_test = y_iq.iloc[train_index], y_iq.iloc[test_index]\n",
    "    print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model predictions for San Jose (sj)\n",
    "bl_pred_train = np.tile(np.mean(y_train_sj), len(y_train_sj))\n",
    "bl_pred_test = np.tile(np.mean(y_test_sj), len(y_test_sj))\n",
    "regression_evaluation(y_train_sj, y_test_sj, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model predictions for Iquitos (Iq)\n",
    "bl_pred_train = np.tile(np.mean(y_train_iq), len(y_train_iq))\n",
    "bl_pred_test = np.tile(np.mean(y_test_iq), len(y_test_iq))\n",
    "regression_evaluation(y_train_iq, y_test_iq, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree model for IQ\n",
    "rf_model(X_train_iq, y_train_iq, X_test_iq, y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree model for SJ \n",
    "rf_model(X_train_sj, y_train_sj, X_test_sj, y_test_sj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with chosen model and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run pipeline on dataset including test_features, and then take only test_features to run the final model\n",
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=True)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=True)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=True)\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "\n",
    "# Run feature engineering \n",
    "train_iq = fe.cyclical_encode_date(train_iq)\n",
    "train_sj = fe.cyclical_encode_date(train_sj)\n",
    "train_iq = fe.drop_date(train_iq)\n",
    "train_sj = fe.drop_date(train_sj)\n",
    "\n",
    "# Split into to final test_features DataFrames\n",
    "test_iq = train_iq.loc[train_iq['total_cases'] < 0, train_iq.columns != 'total_cases']\n",
    "X_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns != 'total_cases']\n",
    "y_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns == 'total_cases']\n",
    "test_sj = train_sj.loc[train_sj['total_cases'] < 0, train_sj.columns != 'total_cases']\n",
    "X_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns != 'total_cases']\n",
    "y_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns == 'total_cases']\n",
    "assert len(X_iq) == len(y_iq)\n",
    "assert len(X_sj) == len(y_sj)\n",
    "assert test_iq.shape[1] == X_iq.shape[1]\n",
    "assert test_sj.shape[1] == X_sj.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data and chosen model and hyperparameters for final prediction\n",
    "\n",
    "# Iquitos, iq\n",
    "final_test_iq = test_iq\n",
    "X_train_iq = X_iq\n",
    "y_train_iq = y_iq\n",
    "model_iq = 'RandomForestRegressor'\n",
    "params_iq = {}\n",
    "\n",
    "# San Jose, sj\n",
    "final_test_sj = test_sj\n",
    "X_train_sj = X_sj\n",
    "y_train_sj = y_sj\n",
    "model_sj = 'RandomForestRegressor'\n",
    "params_sj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final predictions and reformat for submission\n",
    "final_iq = fp.final_predict(final_test_iq, X_train_iq, y_train_iq, \n",
    "              city='iq', model=model_iq, params=params_iq)\n",
    "final_sj = fp.final_predict(final_test_sj, X_train_sj, y_train_sj, \n",
    "              city='sj', model=model_sj, params=params_sj)\n",
    "\n",
    "# Merge the two cities into one DataFrame and write to new csv file \n",
    "fp.write_submission(final_iq, final_sj) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSR-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
