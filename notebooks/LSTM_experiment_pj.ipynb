{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Pipeline**\n",
    "\n",
    "| **Steps**                                              | **Script files**                          |\n",
    "|-----------------------------------------------------------|-------------------------------------------|\n",
    "| 1) Read and pre-process data                              | pre_processing.py                         |\n",
    "| 2) Feature engineering                                    | feature_engineering.py                    |\n",
    "| 3) Train models                                           | model_training.py, <br>tree_model_training.py |\n",
    "| 4) Predict on test_features <br>and write submission file | final_predict.py                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.pre_processing as pp\n",
    "import scripts.feature_engineering as fe\n",
    "import scripts.model_evaluation as me\n",
    "from scripts.model_training import Model\n",
    "from scripts.tree_model_training import rf_model\n",
    "from scripts.model_evaluation import regression_evaluation\n",
    "import scripts.final_predict as fp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files \n",
    "train_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "train_target = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iq shape: (520, 24)\n",
      "train_sj shape: (928, 24)\n"
     ]
    }
   ],
   "source": [
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=False)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True)\n",
    "\n",
    "# Run checks for missing values\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "print(f'train_iq shape: {train_iq.shape}') \n",
    "print(f'train_sj shape: {train_sj.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.boxplot(train_sj['total_cases'])\n",
    "d = train_iq.loc[train_iq['total_cases'] <80, :] \n",
    "plt.boxplot(d['total_cases'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature engineering \n",
    "train_iq = fe.feature_engineer_1(train_iq)\n",
    "train_sj = fe.feature_engineer_1(train_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and cross-validation sets\n",
    "X_train_sj, y_train_sj, X_test_sj, y_test_sj = pp.train_cv_split(train_sj, city='sj')\n",
    "X_train_iq, y_train_iq, X_test_iq, y_test_iq = pp.train_cv_split(train_iq, city='iq')\n",
    "\n",
    "# Check compatible sizes for models:\n",
    "assert len(X_train_sj) == len(y_train_sj)\n",
    "assert len(X_test_sj) == len(y_test_sj)\n",
    "assert len(X_train_iq) == len(y_train_iq)\n",
    "assert len(X_test_iq) == len(y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 23) (130, 23)\n",
      "(260, 23) (130, 23)\n",
      "(390, 23) (130, 23)\n"
     ]
    }
   ],
   "source": [
    "# Train test split with sklearn \n",
    "tss = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "X_iq = train_iq.drop(labels=['total_cases'], axis=1)\n",
    "y_iq = train_iq['total_cases']\n",
    "X_sj = train_sj.drop(labels=['total_cases'], axis=1)\n",
    "y_sj = train_sj['total_cases']\n",
    "\n",
    "for train_index, test_index in tss.split(X_iq):\n",
    "    X_train, X_test = X_iq.iloc[train_index, :], X_iq.iloc[test_index,:]\n",
    "    y_train, y_test = y_iq.iloc[train_index], y_iq.iloc[test_index]\n",
    "    print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model predictions for San Jose (sj)\n",
    "bl_pred_train = np.tile(np.mean(y_train_sj), len(y_train_sj))\n",
    "bl_pred_test = np.tile(np.mean(y_test_sj), len(y_test_sj))\n",
    "regression_evaluation(y_train_sj, y_test_sj, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model predictions for Iquitos (Iq)\n",
    "bl_pred_train = np.tile(np.mean(y_train_iq), len(y_train_iq))\n",
    "bl_pred_test = np.tile(np.mean(y_test_iq), len(y_test_iq))\n",
    "regression_evaluation(y_train_iq, y_test_iq, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree model for IQ\n",
    "rf_model(X_train_iq, y_train_iq, X_test_iq, y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree model for SJ \n",
    "rf_model(X_train_sj, y_train_sj, X_test_sj, y_test_sj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with chosen model and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run pipeline on dataset including test_features, and then take only test_features to run the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data and chosen model and hyperparameters for final prediction\n",
    "\n",
    "# Iquitos, iq\n",
    "final_test_iq = train_iq.drop(['total_cases'], axis=1)\n",
    "X_train_iq = X_train_iq\n",
    "y_train_iq = y_train_iq\n",
    "model_iq = 'RandomForestRegressor'\n",
    "params_iq = {}\n",
    "\n",
    "# San Jose, sj\n",
    "final_test_sj = train_sj.drop(['total_cases'], axis=1)\n",
    "X_train_sj = X_train_sj\n",
    "y_train_sj = y_train_sj\n",
    "model_sj = 'RandomForestRegressor'\n",
    "params_sj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final predictions and reformat for submission\n",
    "final_iq = fp.final_predict(final_test_iq, X_train_iq, y_train_iq, \n",
    "              city='iq', model=model_iq, params=params_iq)\n",
    "final_sj = fp.final_predict(final_test_sj, X_train_sj, y_train_sj, \n",
    "              city='sj', model=model_sj, params=params_sj)\n",
    "\n",
    "# Merge the two cities into one DataFrame and write to new csv file \n",
    "fp.write_submission(final_iq, final_sj) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSR-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
