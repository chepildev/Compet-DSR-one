{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Pipeline**\n",
    "\n",
    "| **Steps**                                              | **Script files**                          |\n",
    "|-----------------------------------------------------------|-------------------------------------------|\n",
    "| 1) Read and pre-process data                              | pre_processing.py                         |\n",
    "| 2) Feature engineering                                    | feature_engineering.py                    |\n",
    "| 3) Train models                                           | model_training.py, <br>tree_model_training.py |\n",
    "| 4) Predict on test_features <br>and write submission file | final_predict.py                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.pre_processing as pp\n",
    "import scripts.feature_engineering as fe\n",
    "import scripts.model_evaluation as me\n",
    "from scripts.model_training import Model\n",
    "import scripts.tree_model_training as tm\n",
    "from scripts.model_evaluation import regression_evaluation\n",
    "import scripts.final_predict as fp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files \n",
    "train_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "train_target = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iq shape: (518, 24)\n",
      "train_sj shape: (928, 24)\n"
     ]
    }
   ],
   "source": [
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=False)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=False)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=False)\n",
    "\n",
    "# Run checks for missing values\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "print(f'train_iq shape: {train_iq.shape}') \n",
    "print(f'train_sj shape: {train_sj.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X_iq = train_iq.drop(labels=['total_cases'], axis=1)\n",
    "y_iq = train_iq['total_cases']\n",
    "X_sj = train_sj.drop(labels=['total_cases'], axis=1)\n",
    "y_sj = train_sj['total_cases']\n",
    "assert len(X_iq) == len(y_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature engineering \n",
    "X_iq = fe.cyclical_encode_date(X_iq)\n",
    "X_sj = fe.cyclical_encode_date(X_sj)\n",
    "X_iq = fe.shift_features(X_iq, periods=1)\n",
    "X_sj = fe.shift_features(X_sj, periods=1)\n",
    "X_iq = fe.drop_date(X_iq)\n",
    "X_sj = fe.drop_date(X_sj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Iquitos: \n",
      "\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 9.072430947354988\n",
      "        RMSE test: 9.072430947354988\n",
      "        MAE train: 6.220546801627883\n",
      "        MAE test: 6.220546801627883 \n",
      "    \n",
      "For San Jose: \n",
      "\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 39.06484683794444\n",
      "        RMSE test: 39.06484683794444\n",
      "        MAE train: 24.198600995838284\n",
      "        MAE test: 24.198600995838284 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39.06484683794444, 39.06484683794444, 24.198600995838284, 24.198600995838284)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model predictions for Iquitos (Iq)\n",
    "bl_pred_train = np.tile(np.mean(y_iq), len(y_iq))\n",
    "bl_pred_test = np.tile(np.mean(y_iq), len(y_iq))\n",
    "print('For Iquitos: ')\n",
    "regression_evaluation(y_iq, y_iq, bl_pred_train, bl_pred_test)\n",
    "\n",
    "# Baseline model predictions for San Jose (sj)\n",
    "bl_pred_train = np.tile(np.mean(y_sj), len(y_sj))\n",
    "bl_pred_test = np.tile(np.mean(y_sj), len(y_sj))\n",
    "print('For San Jose: ')\n",
    "regression_evaluation(y_sj, y_sj, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSS iteration</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.968666</td>\n",
       "      <td>0.185971</td>\n",
       "      <td>0.125537</td>\n",
       "      <td>6.386428</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.967792</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>6.387295</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.877454</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.356672</td>\n",
       "      <td>7.035071</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11.875514</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>0.076362</td>\n",
       "      <td>7.050161</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TSS iteration  rmse_test  rmse_train  mae_train  mae_test  learning_rate   \n",
       "0              1   8.968666    0.185971   0.125537  6.386428            0.1  \\\n",
       "1              1   8.967792    0.008658   0.005863  6.387295            0.1   \n",
       "2              2  11.877454    0.507538   0.356672  7.035071            0.1   \n",
       "3              2  11.875514    0.108966   0.076362  7.050161            0.1   \n",
       "\n",
       "   n_estimators  max_depth  subsample  colsample_bytree  reg_lambda  \n",
       "0           100          5        1.0               1.0           2  \n",
       "1           200          5        1.0               1.0           2  \n",
       "2           100          5        1.0               1.0           2  \n",
       "3           200          5        1.0               1.0           2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XG boost model for iq\n",
    "X, y = X_iq, y_iq\n",
    "tm.xg_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSS iteration</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43.618572</td>\n",
       "      <td>1.682272</td>\n",
       "      <td>1.185423</td>\n",
       "      <td>26.427041</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43.673370</td>\n",
       "      <td>0.256781</td>\n",
       "      <td>0.174029</td>\n",
       "      <td>26.518406</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>37.038379</td>\n",
       "      <td>5.631207</td>\n",
       "      <td>3.957482</td>\n",
       "      <td>27.439259</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37.290659</td>\n",
       "      <td>1.717175</td>\n",
       "      <td>1.203274</td>\n",
       "      <td>27.637586</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TSS iteration  rmse_test  rmse_train  mae_train   mae_test  learning_rate   \n",
       "0              1  43.618572    1.682272   1.185423  26.427041            0.1  \\\n",
       "1              1  43.673370    0.256781   0.174029  26.518406            0.1   \n",
       "2              2  37.038379    5.631207   3.957482  27.439259            0.1   \n",
       "3              2  37.290659    1.717175   1.203274  27.637586            0.1   \n",
       "\n",
       "   n_estimators  max_depth  subsample  colsample_bytree  reg_lambda  \n",
       "0           100          5        1.0               1.0           2  \n",
       "1           200          5        1.0               1.0           2  \n",
       "2           100          5        1.0               1.0           2  \n",
       "3           200          5        1.0               1.0           2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XG boost model for sj\n",
    "X, y = X_sj, y_sj\n",
    "tm.xg_model(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with chosen model and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run pipeline on dataset including test_features, and then take only test_features to run the final model\n",
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=True)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=True)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=True)\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "\n",
    "# Split data into X and y\n",
    "X_iq_comb = train_iq.drop(labels=['total_cases'], axis=1)\n",
    "y_train_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns == 'total_cases']\n",
    "y_test_iq = train_iq.loc[train_iq['total_cases'] < 0, train_iq.columns == 'total_cases']\n",
    "X_sj_comb = train_sj.drop(labels=['total_cases'], axis=1)\n",
    "y_train_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns == 'total_cases']\n",
    "y_test_sj = train_sj.loc[train_sj['total_cases'] < 0, train_sj.columns == 'total_cases']\n",
    "\n",
    "# Run feature engineering \n",
    "X_iq_comb = fe.cyclical_encode_date(X_iq_comb)\n",
    "X_sj_comb = fe.cyclical_encode_date(X_sj_comb)\n",
    "X_iq_comb = fe.shift_features(X_iq_comb, periods=1)\n",
    "X_sj_comb = fe.shift_features(X_sj_comb, periods=1)\n",
    "X_iq_comb = fe.drop_date(X_iq_comb)\n",
    "X_sj_comb = fe.drop_date(X_sj_comb)\n",
    "\n",
    "# Take now only the test features \n",
    "X_train_iq = X_iq_comb.iloc[:(X_iq_comb.shape[0] - y_test_iq.shape[0] + 1) , :]\n",
    "X_train_sj = X_sj_comb.iloc[:(X_sj_comb.shape[0] - y_test_sj.shape[0] + 1) , :]\n",
    "X_test_iq = X_iq_comb.iloc[(X_iq_comb.shape[0] - y_test_iq.shape[0]): , :]\n",
    "X_test_sj = X_sj_comb.iloc[(X_sj_comb.shape[0] - y_test_sj.shape[0]): , :]\n",
    "assert (X_train_iq.shape[0] == y_train_iq.shape[0])\n",
    "assert (X_train_sj.shape[0] == y_train_sj.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data and chosen model and hyperparameters for final prediction\n",
    "\n",
    "params = dict(learning_rate=0.1,\n",
    "        n_estimators=150,\n",
    "        max_depth=5,\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0,\n",
    "        reg_lambda=2)\n",
    "\n",
    "# Iquitos, iq\n",
    "X_test_iq = X_test_iq\n",
    "X_train_iq = X_train_iq\n",
    "y_train_iq = y_train_iq\n",
    "model_iq = 'XGBRegressor'\n",
    "params_iq = params\n",
    "\n",
    "# San Jose, sj\n",
    "X_test_sj = X_test_sj\n",
    "X_train_sj = X_train_sj\n",
    "y_train_sj = y_train_sj\n",
    "model_sj = 'XGBRegressor'\n",
    "params_sj = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final predictions and reformat for submission\n",
    "final_iq = fp.final_predict(X_test_iq, X_train_iq, y_train_iq, \n",
    "              city='iq', model=model_iq, params=params_iq)\n",
    "final_sj = fp.final_predict(X_test_sj, X_train_sj, y_train_sj, \n",
    "              city='sj', model=model_sj, params=params_sj)\n",
    "\n",
    "#final_comb = fp.write_submission(final_iq, final_sj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission file to folder: \n"
     ]
    }
   ],
   "source": [
    "# Merge the two cities into one DataFrame and write to new csv file \n",
    "final = pd.concat([final_sj, final_iq], axis=0)\n",
    "final = final.drop(['weekofyear','year'], axis=1)\n",
    "final['weekofyear'] = test_features.loc[:, ['weekofyear']]\n",
    "final['year'] = test_features.loc[:, ['year']]\n",
    "final = final.loc[:, ['city','year','weekofyear','total_cases']]\n",
    "final['total_cases'] = final['total_cases'].astype(int)\n",
    "print('Writing submission file to folder: ')\n",
    "final.to_csv('for_submission.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSR-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
