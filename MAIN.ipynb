{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Pipeline**\n",
    "\n",
    "| **Steps**                                              | **Script files**                          |\n",
    "|-----------------------------------------------------------|-------------------------------------------|\n",
    "| 1) Read and pre-process data                              | pre_processing.py                         |\n",
    "| 2) Feature engineering                                    | feature_engineering.py                    |\n",
    "| 3) Train models                                           | model_training.py, <br>tree_model_training.py |\n",
    "| 4) Predict on test_features <br>and write submission file | final_predict.py                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.pre_processing as pp\n",
    "import scripts.feature_engineering as fe\n",
    "import scripts.model_evaluation as me\n",
    "from scripts.model_training import Model\n",
    "from scripts.tree_model_training import rf_model\n",
    "from scripts.model_evaluation import regression_evaluation\n",
    "import scripts.final_predict as fp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files \n",
    "train_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "train_target = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iq shape: (518, 24)\n",
      "train_sj shape: (928, 24)\n"
     ]
    }
   ],
   "source": [
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=False)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=False)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=False)\n",
    "\n",
    "# Run checks for missing values\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "print(f'train_iq shape: {train_iq.shape}') \n",
    "print(f'train_sj shape: {train_sj.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature engineering \n",
    "train_iq = fe.cyclical_encode_date(train_iq)\n",
    "train_sj = fe.cyclical_encode_date(train_sj)\n",
    "\n",
    "train_iq = fe.drop_date(train_iq)\n",
    "train_sj = fe.drop_date(train_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and cross-validation sets\n",
    "X_train_sj, y_train_sj, X_test_sj, y_test_sj = pp.train_cv_split(train_sj, city='sj')\n",
    "X_train_iq, y_train_iq, X_test_iq, y_test_iq = pp.train_cv_split(train_iq, city='iq')\n",
    "\n",
    "# Check compatible sizes for models:\n",
    "assert len(X_train_sj) == len(y_train_sj)\n",
    "assert len(X_test_sj) == len(y_test_sj)\n",
    "assert len(X_train_iq) == len(y_train_iq)\n",
    "assert len(X_test_iq) == len(y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 26) (129, 26)\n",
      "(260, 26) (129, 26)\n",
      "(389, 26) (129, 26)\n"
     ]
    }
   ],
   "source": [
    "# Train test split with sklearn \n",
    "tss = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "X_iq = train_iq.drop(labels=['total_cases'], axis=1)\n",
    "y_iq = train_iq['total_cases']\n",
    "X_sj = train_sj.drop(labels=['total_cases'], axis=1)\n",
    "y_sj = train_sj['total_cases']\n",
    "\n",
    "for train_index, test_index in tss.split(X_iq):\n",
    "    X_train, X_test = X_iq.iloc[train_index, :], X_iq.iloc[test_index,:]\n",
    "    y_train, y_test = y_iq.iloc[train_index], y_iq.iloc[test_index]\n",
    "    print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 42.77395132680239\n",
      "        RMSE test: 26.424758032157015\n",
      "        MAE train: 26.39839012792388\n",
      "        MAE test: 16.795393417771038 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42.77395132680239, 26.424758032157015, 26.39839012792388, 16.795393417771038)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model predictions for San Jose (sj)\n",
    "bl_pred_train = np.tile(np.mean(y_train_sj), len(y_train_sj))\n",
    "bl_pred_test = np.tile(np.mean(y_test_sj), len(y_test_sj))\n",
    "regression_evaluation(y_train_sj, y_test_sj, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 9.072430947354988\n",
      "        RMSE test: 9.072430947354988\n",
      "        MAE train: 6.220546801627883\n",
      "        MAE test: 6.220546801627883 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.072430947354988, 9.072430947354988, 6.220546801627883, 6.220546801627883)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model predictions for Iquitos (Iq)\n",
    "bl_pred_train = np.tile(np.mean(y_train_iq), len(y_train_iq))\n",
    "bl_pred_test = np.tile(np.mean(y_test_iq), len(y_test_iq))\n",
    "regression_evaluation(y_train_iq, y_test_iq, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    RandomForestRegressor with params: {}\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 2.6766323277134303\n",
      "        RMSE test: 2.6766323277134303\n",
      "        MAE train: 1.6337451737451736\n",
      "        MAE test: 1.6337451737451736 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.6766323277134303,\n",
       " 2.6766323277134303,\n",
       " 1.6337451737451736,\n",
       " 1.6337451737451736)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree model for IQ\n",
    "rf_model(X_train_iq, y_train_iq, X_test_iq, y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    RandomForestRegressor with params: {}\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 9.663175945948824\n",
      "        RMSE test: 28.164195708915067\n",
      "        MAE train: 5.3471073094867805\n",
      "        MAE test: 16.682202797202798 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.663175945948824, 28.164195708915067, 5.3471073094867805, 16.682202797202798)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree model for SJ \n",
    "rf_model(X_train_sj, y_train_sj, X_test_sj, y_test_sj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with chosen model and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run pipeline on dataset including test_features, and then take only test_features to run the final model\n",
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=True)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=True)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=True)\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "\n",
    "# Run feature engineering \n",
    "train_iq = fe.cyclical_encode_date(train_iq)\n",
    "train_sj = fe.cyclical_encode_date(train_sj)\n",
    "train_iq = fe.drop_date(train_iq)\n",
    "train_sj = fe.drop_date(train_sj)\n",
    "\n",
    "# Split into to final test_features DataFrames\n",
    "test_iq = train_iq.loc[train_iq['total_cases'] < 0, train_iq.columns != 'total_cases']\n",
    "X_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns != 'total_cases']\n",
    "y_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns == 'total_cases']\n",
    "test_sj = train_sj.loc[train_sj['total_cases'] < 0, train_sj.columns != 'total_cases']\n",
    "X_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns != 'total_cases']\n",
    "y_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns == 'total_cases']\n",
    "assert len(X_iq) == len(y_iq)\n",
    "assert len(X_sj) == len(y_sj)\n",
    "assert test_iq.shape[1] == X_iq.shape[1]\n",
    "assert test_sj.shape[1] == X_sj.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data and chosen model and hyperparameters for final prediction\n",
    "\n",
    "# Iquitos, iq\n",
    "final_test_iq = test_iq\n",
    "X_train_iq = X_iq\n",
    "y_train_iq = y_iq\n",
    "model_iq = 'RandomForestRegressor'\n",
    "params_iq = {}\n",
    "\n",
    "# San Jose, sj\n",
    "final_test_sj = test_sj\n",
    "X_train_sj = X_sj\n",
    "y_train_sj = y_sj\n",
    "model_sj = 'RandomForestRegressor'\n",
    "params_sj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final predictions and reformat for submission\n",
    "final_iq = fp.final_predict(final_test_iq, X_train_iq, y_train_iq, \n",
    "              city='iq', model=model_iq, params=params_iq)\n",
    "final_sj = fp.final_predict(final_test_sj, X_train_sj, y_train_sj, \n",
    "              city='sj', model=model_sj, params=params_sj)\n",
    "\n",
    "# Merge the two cities into one DataFrame and write to new csv file \n",
    "fp.write_submission(final_iq, final_sj) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSR-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
