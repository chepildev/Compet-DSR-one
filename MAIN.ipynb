{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Pipeline**\n",
    "\n",
    "| **Steps**                                              | **Script files**                          |\n",
    "|-----------------------------------------------------------|-------------------------------------------|\n",
    "| 1) Read and pre-process data                              | pre_processing.py                         |\n",
    "| 2) Feature engineering                                    | feature_engineering.py                    |\n",
    "| 3) Train models                                           | model_training.py, <br>tree_model_training.py |\n",
    "| 4) Predict on test_features <br>and write submission file | final_predict.py                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import scripts.pre_processing as pp\n",
    "import scripts.feature_engineering as fe\n",
    "import scripts.model_evaluation as me\n",
    "from scripts.model_training import Model\n",
    "import scripts.tree_model_training as tm\n",
    "from scripts.model_evaluation import regression_evaluation\n",
    "import scripts.final_predict as fp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files \n",
    "train_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "train_target = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iq shape: (518, 24)\n",
      "train_sj shape: (928, 24)\n"
     ]
    }
   ],
   "source": [
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=False)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=False)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=False)\n",
    "\n",
    "# Run checks for missing values\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "print(f'train_iq shape: {train_iq.shape}') \n",
    "print(f'train_sj shape: {train_sj.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run feature engineering \n",
    "#train_iq = fe.cyclical_encode_date(train_iq)\n",
    "#train_sj = fe.cyclical_encode_date(train_sj)\n",
    "\n",
    "train_iq = fe.drop_date(train_iq)\n",
    "train_sj = fe.drop_date(train_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X_iq = train_iq.drop(labels=['total_cases'], axis=1)\n",
    "y_iq = train_iq['total_cases']\n",
    "X_sj = train_sj.drop(labels=['total_cases'], axis=1)\n",
    "y_sj = train_sj['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and cross-validation sets\n",
    "X_train_sj, y_train_sj, X_test_sj, y_test_sj = pp.train_cv_split(train_sj, city='sj')\n",
    "X_train_iq, y_train_iq, X_test_iq, y_test_iq = pp.train_cv_split(train_iq, city='iq')\n",
    "\n",
    "# Check compatible sizes for models:\n",
    "assert len(X_train_sj) == len(y_train_sj)\n",
    "assert len(X_test_sj) == len(y_test_sj)\n",
    "assert len(X_train_iq) == len(y_train_iq)\n",
    "assert len(X_test_iq) == len(y_test_iq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 42.77395132680239\n",
      "        RMSE test: 26.424758032157015\n",
      "        MAE train: 26.39839012792388\n",
      "        MAE test: 16.795393417771038 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42.77395132680239, 26.424758032157015, 26.39839012792388, 16.795393417771038)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model predictions for San Jose (sj)\n",
    "bl_pred_train = np.tile(np.mean(y_train_sj), len(y_train_sj))\n",
    "bl_pred_test = np.tile(np.mean(y_test_sj), len(y_test_sj))\n",
    "regression_evaluation(y_train_sj, y_test_sj, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 9.072430947354988\n",
      "        RMSE test: 9.072430947354988\n",
      "        MAE train: 6.220546801627883\n",
      "        MAE test: 6.220546801627883 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.072430947354988, 9.072430947354988, 6.220546801627883, 6.220546801627883)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model predictions for Iquitos (Iq)\n",
    "bl_pred_train = np.tile(np.mean(y_train_iq), len(y_train_iq))\n",
    "bl_pred_test = np.tile(np.mean(y_test_iq), len(y_test_iq))\n",
    "regression_evaluation(y_train_iq, y_test_iq, bl_pred_train, bl_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    RandomForestRegressor with params: {}\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 2.711479244087937\n",
      "        RMSE test: 2.711479244087937\n",
      "        MAE train: 1.6680694980694981\n",
      "        MAE test: 1.6680694980694981 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.711479244087937, 2.711479244087937, 1.6680694980694981, 1.6680694980694981)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree model for IQ\n",
    "tm.rf_model(X_train_iq, y_train_iq, X_test_iq, y_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    RandomForestRegressor with params: {}\n",
      "    Evaluation metrics:\n",
      "        RMSE train: 9.986098805958408\n",
      "        RMSE test: 28.485665945097097\n",
      "        MAE train: 5.469720062208398\n",
      "        MAE test: 16.687202797202797 \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.986098805958408, 28.485665945097097, 5.469720062208398, 16.687202797202797)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree model for SJ \n",
    "tm.rf_model(X_train_sj, y_train_sj, X_test_sj, y_test_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSS iteration</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>reg_lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.404990</td>\n",
       "      <td>0.179380</td>\n",
       "      <td>0.111742</td>\n",
       "      <td>5.465261</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.396832</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>5.456236</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.305093</td>\n",
       "      <td>0.740652</td>\n",
       "      <td>0.509354</td>\n",
       "      <td>6.922478</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11.288674</td>\n",
       "      <td>0.171332</td>\n",
       "      <td>0.113673</td>\n",
       "      <td>6.928529</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TSS iteration  rmse_test  rmse_train  mae_train  mae_test  learning_rate   \n",
       "0              1   8.404990    0.179380   0.111742  5.465261            0.1  \\\n",
       "1              1   8.396832    0.009640   0.006310  5.456236            0.1   \n",
       "2              2  11.305093    0.740652   0.509354  6.922478            0.1   \n",
       "3              2  11.288674    0.171332   0.113673  6.928529            0.1   \n",
       "\n",
       "   n_estimators  max_depth  subsample  colsample_bytree  reg_lambda  \n",
       "0           100          5        1.0               1.0           2  \n",
       "1           200          5        1.0               1.0           2  \n",
       "2           100          5        1.0               1.0           2  \n",
       "3           200          5        1.0               1.0           2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XG boost model for iq\n",
    "X, y = X_iq, y_iq\n",
    "tm.xg_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG boost model for sj\n",
    "X, y = X_sj, y_sj\n",
    "tm.xg_model(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data with chosen model and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run pipeline on dataset including test_features, and then take only test_features to run the final model\n",
    "# Merge features and target data\n",
    "data = pp.merge_data(train_features, train_target, test_features, inc_test=True)\n",
    "\n",
    "# Run processing and split by city\n",
    "train_iq = pp.pre_process(data, 'iq', remove_anomalies=True, inc_test=True)\n",
    "train_sj = pp.pre_process(data, 'sj', remove_anomalies=True, inc_test=True)\n",
    "assert train_iq.isnull().any().any() == False\n",
    "assert train_sj.isnull().any().any() == False\n",
    "\n",
    "# Run feature engineering \n",
    "train_iq = fe.cyclical_encode_date(train_iq)\n",
    "train_sj = fe.cyclical_encode_date(train_sj)\n",
    "train_iq = fe.drop_date(train_iq)\n",
    "train_sj = fe.drop_date(train_sj)\n",
    "\n",
    "# Split into to final test_features DataFrames\n",
    "test_iq = train_iq.loc[train_iq['total_cases'] < 0, train_iq.columns != 'total_cases']\n",
    "X_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns != 'total_cases']\n",
    "y_iq = train_iq.loc[train_iq['total_cases'] >= 0, train_iq.columns == 'total_cases']\n",
    "test_sj = train_sj.loc[train_sj['total_cases'] < 0, train_sj.columns != 'total_cases']\n",
    "X_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns != 'total_cases']\n",
    "y_sj = train_sj.loc[train_sj['total_cases'] >= 0, train_sj.columns == 'total_cases']\n",
    "assert len(X_iq) == len(y_iq)\n",
    "assert len(X_sj) == len(y_sj)\n",
    "assert test_iq.shape[1] == X_iq.shape[1]\n",
    "assert test_sj.shape[1] == X_sj.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data and chosen model and hyperparameters for final prediction\n",
    "\n",
    "# Iquitos, iq\n",
    "final_test_iq = test_iq\n",
    "X_train_iq = X_iq\n",
    "y_train_iq = y_iq\n",
    "model_iq = 'RandomForestRegressor'\n",
    "params_iq = {}\n",
    "\n",
    "# San Jose, sj\n",
    "final_test_sj = test_sj\n",
    "X_train_sj = X_sj\n",
    "y_train_sj = y_sj\n",
    "model_sj = 'RandomForestRegressor'\n",
    "params_sj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final predictions and reformat for submission\n",
    "final_iq = fp.final_predict(final_test_iq, X_train_iq, y_train_iq, \n",
    "              city='iq', model=model_iq, params=params_iq)\n",
    "final_sj = fp.final_predict(final_test_sj, X_train_sj, y_train_sj, \n",
    "              city='sj', model=model_sj, params=params_sj)\n",
    "\n",
    "# Merge the two cities into one DataFrame and write to new csv file \n",
    "final_comb = fp.write_submission(final_iq, final_sj) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSR-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
